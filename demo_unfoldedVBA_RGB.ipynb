{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The demo file of unfoledVBA for RGB images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Test set\n",
      "Loading Train set\n",
      "Loading Train RGB set\n",
      "Loading Train RGB set\n",
      "Loading Test RGB set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "%matplotlib inline\n",
    "import time\n",
    "import random\n",
    "from Model_files.unfoldedVBA_vec_RGB import VBA_class\n",
    "from Model_files.tools import *\n",
    "from Model_files.model_vec import *\n",
    "from Model_files.initializationdic_RGB import *\n",
    "import cv2\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Test saved models\n",
    "### 1.1- Test conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset         = 'Flickr30'  \n",
    "name_kernel     = 'Mixed' \n",
    "noise_std_min   = 0.005 \n",
    "noise_std_max   = 0.05 \n",
    "noise_std_range = [noise_std_min, noise_std_max] # one random noise std\n",
    "device = 'GPU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "Testset: Flickr30\n",
      "Blur   : Mixed\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "im_size         = (256,256)\n",
    "im_range        = [0,1]       # minimal and maximal pixel values\n",
    "test_conditions = [name_kernel, noise_std_range, im_size, im_range]\n",
    "\n",
    "# Path to the train/val/test set and to the folder with the saved model\n",
    "path_trainset      = 'Datasets/Trainsets_RGB'\n",
    "path_valset        = 'Datasets/Valsets_RGB'\n",
    "path_testset       = 'Datasets/Testsets_RGB'\n",
    "path_save          = os.path.join('Trainings',name_kernel,'saved_model')\n",
    "paths              = [path_testset,path_trainset,path_valset,path_save]\n",
    "\n",
    "print('--------------------------------------------------------------------------------------------------------------------------------')\n",
    "print('Testset: %s'%(dataset))\n",
    "print('Blur   : %s'%(name_kernel))\n",
    "print('--------------------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1- Change RGB image $\\in$ [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_rgb = 'Datasets/Groundtruth/full/' + dataset\n",
    "path_rgb_nor = 'Datasets/Groundtruth/full1_RGB/'+ dataset# normalized RGB image saved here\n",
    "# create the path if it does not exist \n",
    "if not os.path.exists(path_rgb_nor):\n",
    "    os.makedirs(path_rgb_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name in os.listdir(os.path.join(path_rgb)):\n",
    "    if img_name =='.ipynb_checkpoints': continue\n",
    "    path_read = os.path.join(path_rgb,img_name)\n",
    "    image = cv2.cvtColor(cv2.imread(path_read), cv2.COLOR_BGR2RGB)\n",
    "    nor_image = (image-image.min())/(image.max()-image.min()) # the normalization of the image\n",
    "    path_save = os.path.join(path_rgb_nor,str(os.path.splitext(img_name)[0])+'.mat')\n",
    "    sio.savemat(path_save, {'image': nor_image})    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2- Create blurred test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_testset = len([n for n in os.listdir(os.path.join('Datasets/Groundtruth/full1_RGB',dataset))]) # number of test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The size of the test set is',size_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--------------------------------------------------------------------------------------------------------------------------------',flush=True)\n",
    "print('Creating %d blurred test images from %s using %s blur kernel...'%(size_testset,dataset,name_kernel),flush=True)\n",
    "create_testset_RGB(dataset,'Datasets/Groundtruth',path_testset,name_kernel,noise_std_range,im_size)\n",
    "print('--------------------------------------------------------------------------------------------------------------------------------',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3- Load a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the model learned by greedy approach or N-N training\n",
    "saved_model = 'greedy_approach'\n",
    "#saved_model = 'N-N training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if saved_model == 'greedy_approach':\n",
    "    path_save_block = os.path.join('Trainings',name_kernel,'final_model_greedy_block22')\n",
    "else:\n",
    "    path_save_block = os.path.join('Trainings',name_kernel,'final_model_N_N_bloc22')\n",
    "paths              = [path_testset,path_trainset,path_valset,path_save] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network              = VBA_class(test_conditions, paths, mode='test',device = device)\n",
    "path_layers          = os.path.join(path_save_block,'trained_model_MinLossOnVal.pt')\n",
    "path_post_processing = os.path.join(path_save_block,'trained_post-processing_MinLossOnVal.pt')\n",
    "network.model.load_state_dict(torch.load(path_layers))\n",
    "network.last_layer.load_state_dict(torch.load(path_post_processing))\n",
    "if device == 'CPU': \n",
    "    network.to('cpu')  \n",
    "print('--------------------------------------------------------------------------------------------------------------------------------',flush=True)\n",
    "print('Loaded unfoldedVBA layers from %s.'%(path_layers))\n",
    "print('Loaded the post-processing layer from %s.'%(path_post_processing))\n",
    "print('--------------------------------------------------------------------------------------------------------------------------------',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in network.model.state_dict():\n",
    "    print(param_tensor, \"\\t\", network.model.state_dict()[param_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "i = 11\n",
    "no_param = 21#block\n",
    "for f in network.parameters():\n",
    "    if k == no_param*i:\n",
    "        conv3_weight = f.data\n",
    "        print('conv3_weight is',conv3_weight)\n",
    "    elif k == no_param*i+1:\n",
    "        #print('This is',k)\n",
    "        conv3_bias = f.data\n",
    "    elif k == no_param*i+2:\n",
    "        #print('This is',k)\n",
    "        conv2_weight = f.data\n",
    "    elif k == no_param*i+3:\n",
    "        #print('This is',k)\n",
    "        conv2_bias = f.data\n",
    "    elif k == no_param*i+4:\n",
    "        #print('This is',k)\n",
    "        lin1_weight = f.data\n",
    "    elif k == no_param*i+5:\n",
    "        #print('This is',k)\n",
    "        lin1_bias = f.data\n",
    "    elif k == no_param*i+6:\n",
    "        #print('This is',k)\n",
    "        lin3_weight = f.data\n",
    "    elif k == no_param*i+7:\n",
    "        #print('This is',k)\n",
    "        lin3_bias = f.data\n",
    "    elif k == no_param*i+8:\n",
    "        #print('This is',k)\n",
    "        a_k = f.data\n",
    "    elif k == no_param*i+9:\n",
    "        #print('This is',k)\n",
    "        b_k = f.data \n",
    "    elif k == no_param*i+10:\n",
    "        #print('This is',k)\n",
    "        Haar = f.data     \n",
    "    k += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block5 = {}\n",
    "block5['conv3_weight'] = conv3_weight\n",
    "block5['conv3_bias'] = conv3_bias\n",
    "block5['conv2_weight'] = conv2_weight\n",
    "block5['conv2_bias'] = conv2_bias\n",
    "block5['lin1_weight'] = lin1_weight\n",
    "block5['lin1_bias'] = lin1_bias\n",
    "block5['lin3_weight'] = lin3_weight\n",
    "block5['lin3_bias'] = lin3_bias\n",
    "block5['a_k'] = a_k\n",
    "block5['b_k'] = b_k\n",
    "block5['Haar'] = Haar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "import pickle\n",
    "with open('block0_greedy_RGB.txt', 'wb') as handle:\n",
    "    pickle.dump(block5, handle)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4- Test a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--------------------------------------------------------------------------------------------------------------------------------',flush=True)\n",
    "print('Testing model %s ...'%(path_save),flush=True)\n",
    "time_start = time.time()\n",
    "network.test(dataset)\n",
    "time_per_image = (time.time()-time_start)/size_testset\n",
    "print('Average time per image: %.2f seconds'%(time_per_image),flush=True)\n",
    "print('--------------------------------------------------------------------------------------------------------------------------------',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Train a model\n",
    "### 2.1- Change RGB $\\in$ [0,1] for training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_rgb = 'Datasets/BSD500_COCO1000_train_val/train'\n",
    "# path_rgb_nor = 'Datasets/BSD500_COCO1000_train_val/train1_RGB'\n",
    "# # create the path if it does not exist \n",
    "# if not os.path.exists(path_rgb_nor):\n",
    "#     os.makedirs(path_rgb_nor)\n",
    "\n",
    "path_rgb = 'Datasets/BSD500_COCO1000_train_val/val'\n",
    "path_rgb_nor = 'Datasets/BSD500_COCO1000_train_val/val1_RGB'\n",
    "# create the path if it does not exist \n",
    "if not os.path.exists(path_rgb_nor):\n",
    "    os.makedirs(path_rgb_nor)\n",
    "\n",
    "for img_name in os.listdir(path_rgb):\n",
    "    if img_name != '.ipynb_checkpoints':\n",
    "        path_read = os.path.join(path_rgb,img_name)\n",
    "        image = cv2.cvtColor(cv2.imread(path_read), cv2.COLOR_BGR2RGB)\n",
    "        nor_image = (image-image.min())/(image.max()-image.min()) # the normalization of the image\n",
    "        #print('true image is ',nor_image)\n",
    "        path_save = os.path.join(path_rgb_nor,str(os.path.splitext(img_name)[0])+'.mat')\n",
    "        sio.savemat(path_save, {'image': nor_image})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_rgb = 'Datasets/BSD500_COCO1000_train_val/train_RGB'\n",
    "# path_gray = 'Datasets/BSD500_COCO1000_train_val/train1_RGB'\n",
    "\n",
    "path_rgb = 'Datasets/BSD500_COCO1000_train_val/val_RGB'\n",
    "path_gray = 'Datasets/BSD500_COCO1000_train_val/val1_RGB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_trainset = len([n for n in os.listdir(os.path.join(path_gray)) if n != '.ipynb_checkpoints']) # number of test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The size of the train set is',size_trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2- Center crop image pairs for training and validation and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_groundtruth_train = 'Datasets/BSD500_COCO1000_train_val/train1_RGB'\n",
    "path_trainset = 'Datasets/Trainsets_RGB'\n",
    "# create the path if it does not exist\n",
    "if not os.path.exists(path_trainset):\n",
    "    os.makedirs(path_trainset)\n",
    "im_size         = (256,256)\n",
    "create_trainset_RGB(path_groundtruth_train,path_trainset,noise_std_range,im_size)    \n",
    "\n",
    "path_groundtruth_val = 'Datasets/BSD500_COCO1000_train_val/val1_RGB'\n",
    "path_valset = 'Datasets/Valsets_RGB'\n",
    "# create the path if it does not exist\n",
    "if not os.path.exists(path_valset):\n",
    "    os.makedirs(path_valset)\n",
    "im_size         = (256,256)\n",
    "create_trainset_RGB(path_groundtruth_val,path_valset,noise_std_range,im_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_trainset = len([n for n in os.listdir(os.path.join(path_trainset))]) # number of train images\n",
    "size_valset = len([n for n in os.listdir(os.path.join(path_valset))]) # number of test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The size of the train set is',size_trainset)\n",
    "print('The size of the val set is',size_valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= sio.loadmat('Datasets/Trainsets_RGB/000000001072_blur11.mat')\n",
    "#data= sio.loadmat('Datasets/Valsets_RGB/101085_blur14.mat')\n",
    "image = data['image']\n",
    "trueimage = data['trueimage']\n",
    "h = data['h']\n",
    "noise_std = data['noise_std']\n",
    "plt.figure()\n",
    "plt.imshow(h,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3- Training parameters\n",
    "##### Please refer to unfoldedVBA_vec_RGB.py to see all training parameters (learning rates, batch size, loss function, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_first_layer     = 5e-3  #learning rate to train the first layer\n",
    "lr_greedy          = 1e-3   #learning rate to train the following layers during greedy approach\n",
    "lr_lpp             = 1e-3   #learning rate to train the post-processing layer\n",
    "lr_N_N             = 5e-5  #learning rate to train all the layers together + lpp during greedy approach\n",
    "mode               ='first_layer'    \n",
    "nb_epochs          = [1,1,2,2] #number of epochs for training the first layer, the remaining layers, the post-processing layer, N-N training respectively\n",
    "network            = VBA_class(test_conditions, paths, mode,\n",
    "                         lr_first_layer     = lr_first_layer,\n",
    "                         lr_greedy          = lr_greedy,\n",
    "                         lr_lpp             = lr_lpp,\n",
    "                         lr_N_N             = lr_N_N,\n",
    "                         nb_epochs          = nb_epochs,\n",
    "                         device             = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4- Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(a=1, version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv3_weight is tensor([[[[-2.6845, -4.7743, -4.0976],\n",
      "          [-3.1357, -4.4324, -2.4751],\n",
      "          [-2.2557, -1.6146,  0.5117]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "init(network) # use the initial parameter for the first layer\n",
    "if device == 'CPU': \n",
    "    network.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This line opens a log file\n",
    "with open(\"bug_log.txt\", \"w\") as log:\n",
    "\n",
    "    try:\n",
    "        network.train()\n",
    "        print(\"There is no bug.\", file = log)\n",
    "    except Exception:\n",
    "        traceback.print_exc(file=log) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
